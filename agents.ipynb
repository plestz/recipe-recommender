{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import asyncio\n",
    "\n",
    "from typing import Sequence\n",
    "\n",
    "import autogen\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination, TimeoutTermination, MaxMessageTermination\n",
    "from autogen_agentchat.messages import AgentEvent, ChatMessage, TextMessage, MultiModalMessage\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat, SelectorGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_core import CancellationToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your OPENAI API key\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "# Load your Spoonacular API key\n",
    "if not os.environ.get('SPOONACULAR_API_KEY'):\n",
    "    os.environ['SPOONACULAR_API_KEY'] = getpass.getpass(\"Enter your Spoonacular API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OpenAI model client for inference\n",
    "openai_model_client = OpenAIChatCompletionClient(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "SPOONACULAR_API_BASE_URL = f'https://api.spoonacular.com/recipes/complexSearch'\n",
    "\n",
    "param_schema = pd.read_csv('SpoonacularAPI_InputGuide.csv').to_dict(orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all model tools\n",
    "async def search_web_tool(query: str) -> str:\n",
    "    \"\"\"Searches web for relevant information.\"\"\"\n",
    "    # Call API!\n",
    "    return \"The start was 10 and the end was 15.\"\n",
    "\n",
    "def percentage_change_tool(start: float, end: float) -> float:\n",
    "    \"\"\"Finds the percentage change between start and end.\"\"\"\n",
    "    return ((end - start) / start) * 100\n",
    "\n",
    "def addition_tool(first: float, second: float) -> float:\n",
    "    \"\"\"Adds two numbers together.\"\"\"\n",
    "    return first + second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = UserProxyAgent(\n",
    "    name = \"UserProxyAgent\",\n",
    "    description = \"Proxy agent for user interactions.\",\n",
    ")\n",
    "\n",
    "web_search_agent = AssistantAgent(\n",
    "    name = \"WebSearchAgent\",\n",
    "    model_client = openai_model_client,\n",
    "    description = \"A web search agent for relevant results.\",\n",
    "    tools = [search_web_tool],\n",
    "    system_message = \"\"\"\n",
    "        You are a web search agent.\n",
    "        Your only tool is search_web_tool - use it to find information.\n",
    "        You make only one search call at a time.\n",
    "        Once you have the results, you never do calculations based on them.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "data_manipulator_agent = AssistantAgent(\n",
    "    name = \"DataManipulatorAgent\",\n",
    "    model_client = openai_model_client,\n",
    "    description = \"A data manipulator agent. Useful for performing calculations and ranking items according to relevance.\",\n",
    "    tools = [percentage_change_tool, addition_tool],\n",
    "    system_message = \"\"\"\n",
    "        You are an expert data manipulator agent.\n",
    "        Given the tasks you have been assigned, you should analyze the data and provide results.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "writer_agent = AssistantAgent(\n",
    "    name = \"WriterAgent\",\n",
    "    model_client = openai_model_client,\n",
    "    description = \"A writer agent. All writing should be in English, make sense, and be perfectly clear.\",\n",
    "    system_message = \"\"\"\n",
    "        You are an expert writer, on par with the best in the world.\n",
    "        Given the data that you have received, you should write a full, cohesive, and ranked report about it that is directly in line with the user's request.\n",
    "        You should emphasize and display adherence to all user filters that have been requested.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "parser_agent_system_message = f\"\"\"\n",
    "    You are a strict parameter extraction agent. \n",
    "    You will be given a natural language query and a list of valid parameters, including name, type, example, and description. \n",
    "    Your job is to return a JSON dictionary where each key is the exact 'Name' of a parameter and each value is type-safe and based on the user's query. \n",
    "    Do not include keys that are not present in the schema. \n",
    "    Only use parameters relevant to the query. \n",
    "    If the query is vague, only use 'query'.\n",
    "    \n",
    "    The parameter guidelines are:\n",
    "    {param_schema}\n",
    "\n",
    "    The 'number' parameter is REQUIRED to be greater than 0 and less than 6. If\n",
    "    the user's request is unclear, default to 3. Always include the 'number' parameter.\n",
    "    The 'query' parameter is REQUIRED and should be a string. Always include the 'query' parameter.\n",
    "    All other parameters are OPTIONAL and should be included only if they are relevant to the user's query.\n",
    "\n",
    "    You should return a dictionary in the following format:\n",
    "    {{\"parameter_name\": \"parameter_value\", ...}}\n",
    "\n",
    "    The parameter_name should be the exact name of the parameter in the schema.\n",
    "    The parameter_value should be the value that is relevant to the user's query.\n",
    "\n",
    "    Do not include any other text or explanation.\n",
    "    If you cannot find a parameter that matches the query, return an empty dictionary.\n",
    "    If the query is not valid, return an empty dictionary.\n",
    "    If the query is too vague, return an empty dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "parser_agent = AssistantAgent(\n",
    "    name = 'ParserAgent',\n",
    "    model_client = openai_model_client,\n",
    "    description = 'An agent designed to turn NLP queries into API calls. It will take a user query and a parameter schema, and return a list of parameters that can be used to call the API. The agent will use the parameter schema to determine which parameters are required for the API call. The agent will also use the user query to determine which parameters are relevant for the API call. The agent will return a list of parameters that can be used to call the API.',\n",
    "    system_message = parser_agent_system_message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the multi-agent team, rotation, and termination conditions\n",
    "\n",
    "text_mention_termination = TextMentionTermination(\"APPROVE\")\n",
    "max_messages_termination = MaxMessageTermination(max_messages = 25)\n",
    "# timeout_termination = TimeoutTermination(timeout_seconds = 10)\n",
    "\n",
    "tm_termination = text_mention_termination # | max_messages_termination\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants = [user_agent, parser_agent], \n",
    "    termination_condition = text_mention_termination\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "\n",
      "---------- UserProxyAgent ----------\n",
      "Give me twelve recipes with at most 30 mg of calcium and include milk\n",
      "---------- ParserAgent ----------\n",
      "{\"query\":\"recipes with at most 30 mg of calcium and include milk\",\"number\":3,\"includeIngredients\":\"milk\",\"maxCalcium\":30}\n",
      "---------- UserProxyAgent ----------\n",
      "chicken and pasta\n",
      "---------- ParserAgent ----------\n",
      "{\"query\":\"chicken and pasta\",\"number\":3}\n",
      "---------- UserProxyAgent ----------\n",
      "1 recipe with beef\n",
      "---------- ParserAgent ----------\n",
      "{\"query\":\"recipe with beef\",\"number\":1}\n",
      "---------- UserProxyAgent ----------\n",
      "a lot of carbs in my recipe. lots of crackers\n",
      "---------- ParserAgent ----------\n",
      "{\"query\":\"a lot of carbs in my recipe with lots of crackers\",\"number\":3,\"includeIngredients\":\"crackers\"}\n",
      "---------- UserProxyAgent ----------\n",
      "at least 50 carbs, lots of crackers\n",
      "---------- ParserAgent ----------\n",
      "{\"query\":\"lots of crackers\",\"number\":3,\"includeIngredients\":\"crackers\",\"minCarbs\":50}\n",
      "---------- UserProxyAgent ----------\n",
      "APPROVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='', type='TextMessage'), UserInputRequestedEvent(source='UserProxyAgent', models_usage=None, metadata={}, request_id='6e6aa76b-3e4f-4686-8300-3fc6eddf2e26', content='', type='UserInputRequestedEvent'), TextMessage(source='UserProxyAgent', models_usage=None, metadata={}, content='Give me twelve recipes with at most 30 mg of calcium and include milk', type='TextMessage'), TextMessage(source='ParserAgent', models_usage=RequestUsage(prompt_tokens=4416, completion_tokens=32), metadata={}, content='{\"query\":\"recipes with at most 30 mg of calcium and include milk\",\"number\":3,\"includeIngredients\":\"milk\",\"maxCalcium\":30}', type='TextMessage'), UserInputRequestedEvent(source='UserProxyAgent', models_usage=None, metadata={}, request_id='2e52f07d-f62c-43ef-8be3-0926c3914d50', content='', type='UserInputRequestedEvent'), TextMessage(source='UserProxyAgent', models_usage=None, metadata={}, content='chicken and pasta', type='TextMessage'), TextMessage(source='ParserAgent', models_usage=RequestUsage(prompt_tokens=4466, completion_tokens=13), metadata={}, content='{\"query\":\"chicken and pasta\",\"number\":3}', type='TextMessage'), UserInputRequestedEvent(source='UserProxyAgent', models_usage=None, metadata={}, request_id='c63460e8-8687-442a-8f0f-a00520552d62', content='', type='UserInputRequestedEvent'), TextMessage(source='UserProxyAgent', models_usage=None, metadata={}, content='1 recipe with beef', type='TextMessage'), TextMessage(source='ParserAgent', models_usage=RequestUsage(prompt_tokens=4497, completion_tokens=12), metadata={}, content='{\"query\":\"recipe with beef\",\"number\":1}', type='TextMessage'), UserInputRequestedEvent(source='UserProxyAgent', models_usage=None, metadata={}, request_id='366139cc-5b9c-4a8e-860b-363a5522b0e1', content='', type='UserInputRequestedEvent'), TextMessage(source='UserProxyAgent', models_usage=None, metadata={}, content='a lot of carbs in my recipe. lots of crackers', type='TextMessage'), TextMessage(source='ParserAgent', models_usage=RequestUsage(prompt_tokens=4534, completion_tokens=26), metadata={}, content='{\"query\":\"a lot of carbs in my recipe with lots of crackers\",\"number\":3,\"includeIngredients\":\"crackers\"}', type='TextMessage'), UserInputRequestedEvent(source='UserProxyAgent', models_usage=None, metadata={}, request_id='a2595446-db6c-42d0-b59d-7983d7fc0607', content='', type='UserInputRequestedEvent'), TextMessage(source='UserProxyAgent', models_usage=None, metadata={}, content='at least 50 carbs, lots of crackers', type='TextMessage'), TextMessage(source='ParserAgent', models_usage=RequestUsage(prompt_tokens=4583, completion_tokens=24), metadata={}, content='{\"query\":\"lots of crackers\",\"number\":3,\"includeIngredients\":\"crackers\",\"minCarbs\":50}', type='TextMessage'), UserInputRequestedEvent(source='UserProxyAgent', models_usage=None, metadata={}, request_id='454fdaf4-424d-4d92-888f-5fea63030d31', content='', type='UserInputRequestedEvent'), TextMessage(source='UserProxyAgent', models_usage=None, metadata={}, content='APPROVE', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a task through the multi-agent system\n",
    "await team.reset()\n",
    "\n",
    "task = \"\"\n",
    "\n",
    "await Console(team.run_stream(task = task))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
